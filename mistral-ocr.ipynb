{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c0905be",
   "metadata": {},
   "source": [
    "# Mistral OCR avec Annotations\n",
    "\n",
    "Ce notebook utilise l'API Mistral OCR pour extraire le texte et les images des documents PDF avec des annotations structur√©es.\n",
    "\n",
    "## Fonctionnalit√©s :\n",
    "- Extraction du texte avec conservation de la structure\n",
    "- Extraction et annotation des images, graphiques, tableaux\n",
    "- Export des images extraites dans un dossier\n",
    "- G√©n√©ration d'un fichier Markdown propre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de57882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import json\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from mistralai import Mistral\n",
    "from mistralai.models import OCRResponse\n",
    "from pydantic import BaseModel, Field\n",
    "from enum import Enum\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Charger les variables d'environnement\n",
    "load_dotenv()\n",
    "\n",
    "# Initialiser le client Mistral\n",
    "api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
    "client = Mistral(api_key=api_key)\n",
    "\n",
    "print(\"‚úÖ Client Mistral initialis√© avec succ√®s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c6387c",
   "metadata": {},
   "source": [
    "## D√©finition des mod√®les Pydantic pour les Annotations\n",
    "\n",
    "Nous d√©finissons les sch√©mas pour :\n",
    "- **BBox Annotation** : Type d'image (graphique, tableau, texte, image) et description\n",
    "- **Document Annotation** : Langue, r√©sum√©, auteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c29d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finition des types d'images pour BBox Annotation\n",
    "class ImageType(str, Enum):\n",
    "    GRAPH = \"graph\"\n",
    "    CHART = \"chart\"\n",
    "    TABLE = \"table\"\n",
    "    SCHEMA = \"schema\"\n",
    "    DIAGRAM = \"diagram\"\n",
    "    FIGURE = \"figure\"\n",
    "    IMAGE = \"image\"\n",
    "    TEXT = \"text\"\n",
    "    SIGNATURE = \"signature\"\n",
    "    LOGO = \"logo\"\n",
    "\n",
    "# Mod√®le pour l'annotation des BBox (images extraites)\n",
    "class ImageAnnotation(BaseModel):\n",
    "    image_type: ImageType = Field(..., description=\"Le type de l'image d√©tect√©e (graph, chart, table, schema, diagram, figure, image, text, signature, logo)\")\n",
    "    title: str = Field(..., description=\"Titre ou l√©gende de l'image si disponible\")\n",
    "    short_description: str = Field(..., description=\"Description courte de l'image en fran√ßais\")\n",
    "    detailed_description: str = Field(..., description=\"Description d√©taill√©e du contenu de l'image en fran√ßais\")\n",
    "    data_extracted: str = Field(default=\"\", description=\"Donn√©es extraites si c'est un tableau ou graphique (format texte)\")\n",
    "\n",
    "# Mod√®le pour l'annotation du document complet\n",
    "class DocumentAnnotation(BaseModel):\n",
    "    language: str = Field(..., description=\"Langue du document en format ISO 639-1 (ex: 'fr', 'en')\")\n",
    "    title: str = Field(..., description=\"Titre principal du document\")\n",
    "    document_type: str = Field(..., description=\"Type de document (rapport, proc√®s-verbal, contrat, etc.)\")\n",
    "    summary: str = Field(..., description=\"R√©sum√© complet du document en fran√ßais\")\n",
    "    key_points: list[str] = Field(..., description=\"Points cl√©s du document\")\n",
    "    authors: list[str] = Field(default=[], description=\"Liste des auteurs ou signataires du document\")\n",
    "    date: str = Field(default=\"\", description=\"Date du document si mentionn√©e\")\n",
    "    organizations: list[str] = Field(default=[], description=\"Organisations ou entit√©s mentionn√©es\")\n",
    "\n",
    "print(\"‚úÖ Mod√®les d'annotation d√©finis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a8866c",
   "metadata": {},
   "source": [
    "## Fonctions utilitaires\n",
    "\n",
    "Fonctions pour :\n",
    "- Encoder les fichiers PDF/images en base64\n",
    "- Traiter la r√©ponse OCR\n",
    "- Sauvegarder les images extraites\n",
    "- G√©n√©rer le Markdown final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df14ea90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_file_to_base64(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Encode un fichier (PDF ou image) en base64.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Chemin vers le fichier\n",
    "        \n",
    "    Returns:\n",
    "        Cha√Æne base64 encod√©e\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            return base64.b64encode(file.read()).decode('utf-8')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå Erreur: Le fichier {file_path} n'a pas √©t√© trouv√©.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_mime_type(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    D√©termine le type MIME en fonction de l'extension du fichier.\n",
    "    \"\"\"\n",
    "    ext = Path(file_path).suffix.lower()\n",
    "    mime_types = {\n",
    "        '.pdf': 'application/pdf',\n",
    "        '.png': 'image/png',\n",
    "        '.jpg': 'image/jpeg',\n",
    "        '.jpeg': 'image/jpeg',\n",
    "        '.gif': 'image/gif',\n",
    "        '.webp': 'image/webp',\n",
    "        '.avif': 'image/avif',\n",
    "        '.bmp': 'image/bmp',\n",
    "        '.tiff': 'image/tiff',\n",
    "    }\n",
    "    return mime_types.get(ext, 'application/octet-stream')\n",
    "\n",
    "\n",
    "def save_base64_image(base64_string: str, output_path: str) -> bool:\n",
    "    \"\"\"\n",
    "    Sauvegarde une image base64 vers un fichier.\n",
    "    \n",
    "    Args:\n",
    "        base64_string: Image encod√©e en base64 (peut inclure le pr√©fixe data:...)\n",
    "        output_path: Chemin de sortie pour l'image\n",
    "        \n",
    "    Returns:\n",
    "        True si succ√®s, False sinon\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Retirer le pr√©fixe data:image/...;base64, si pr√©sent\n",
    "        if base64_string.startswith('data:'):\n",
    "            base64_string = base64_string.split(',', 1)[1]\n",
    "        \n",
    "        image_data = base64.b64decode(base64_string)\n",
    "        \n",
    "        with open(output_path, 'wb') as f:\n",
    "            f.write(image_data)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur lors de la sauvegarde de l'image: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def create_output_directory(base_name: str) -> Path:\n",
    "    \"\"\"\n",
    "    Cr√©e le dossier de sortie pour les r√©sultats OCR.\n",
    "    \n",
    "    Args:\n",
    "        base_name: Nom de base du document\n",
    "        \n",
    "    Returns:\n",
    "        Chemin du dossier cr√©√©\n",
    "    \"\"\"\n",
    "    output_dir = Path(\"output\") / base_name\n",
    "    images_dir = output_dir / \"images\"\n",
    "    \n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    images_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    return output_dir\n",
    "\n",
    "\n",
    "print(\"‚úÖ Fonctions utilitaires d√©finies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d27a100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "def parse_document_annotation(annotation_str: str) -> dict:\n",
    "    \"\"\"\n",
    "    Parse l'annotation du document (JSON string) en dictionnaire.\n",
    "    \"\"\"\n",
    "    if not annotation_str:\n",
    "        return {}\n",
    "    try:\n",
    "        return json.loads(annotation_str)\n",
    "    except:\n",
    "        return {\"raw\": annotation_str}\n",
    "\n",
    "\n",
    "def parse_image_annotation(annotation_str: str) -> dict:\n",
    "    \"\"\"\n",
    "    Parse l'annotation d'image (JSON string) en dictionnaire.\n",
    "    \"\"\"\n",
    "    if not annotation_str:\n",
    "        return {}\n",
    "    try:\n",
    "        return json.loads(annotation_str)\n",
    "    except:\n",
    "        return {\"description\": annotation_str}\n",
    "\n",
    "\n",
    "def generate_frontmatter(\n",
    "    source_file: str,\n",
    "    document_annotation: str,\n",
    "    images_info: list[dict],\n",
    "    total_pages: int\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    G√©n√®re le frontmatter YAML pour Astro.\n",
    "    \n",
    "    Args:\n",
    "        source_file: Nom du fichier source\n",
    "        document_annotation: Annotation du document (JSON string)\n",
    "        images_info: Liste des infos sur les images\n",
    "        total_pages: Nombre total de pages\n",
    "        \n",
    "    Returns:\n",
    "        Frontmatter YAML format√©\n",
    "    \"\"\"\n",
    "    # Parser l'annotation du document\n",
    "    doc_data = parse_document_annotation(document_annotation)\n",
    "    \n",
    "    # Construire le frontmatter\n",
    "    frontmatter = {\n",
    "        \"source_file\": source_file,\n",
    "        \"total_pages\": total_pages,\n",
    "        \"total_images\": len(images_info),\n",
    "    }\n",
    "    \n",
    "    # Ajouter les donn√©es du document si disponibles\n",
    "    if doc_data:\n",
    "        if \"title\" in doc_data:\n",
    "            frontmatter[\"title\"] = doc_data.get(\"title\", \"\")\n",
    "        if \"language\" in doc_data:\n",
    "            frontmatter[\"language\"] = doc_data.get(\"language\", \"\")\n",
    "        if \"document_type\" in doc_data:\n",
    "            frontmatter[\"document_type\"] = doc_data.get(\"document_type\", \"\")\n",
    "        if \"summary\" in doc_data:\n",
    "            frontmatter[\"summary\"] = doc_data.get(\"summary\", \"\")\n",
    "        if \"key_points\" in doc_data:\n",
    "            frontmatter[\"key_points\"] = doc_data.get(\"key_points\", [])\n",
    "        if \"authors\" in doc_data:\n",
    "            frontmatter[\"authors\"] = doc_data.get(\"authors\", [])\n",
    "        if \"date\" in doc_data:\n",
    "            frontmatter[\"date\"] = doc_data.get(\"date\", \"\")\n",
    "        if \"organizations\" in doc_data:\n",
    "            frontmatter[\"organizations\"] = doc_data.get(\"organizations\", [])\n",
    "    \n",
    "    # Ajouter les annotations des images\n",
    "    if images_info:\n",
    "        images_data = []\n",
    "        for img in images_info:\n",
    "            img_entry = {\n",
    "                \"id\": img.get(\"id\", \"\"),\n",
    "                \"filename\": img.get(\"filename\", \"\"),\n",
    "                \"page\": img.get(\"page\", 0),\n",
    "            }\n",
    "            \n",
    "            # Parser et ajouter l'annotation de l'image\n",
    "            if \"annotation\" in img and img[\"annotation\"]:\n",
    "                img_annotation = parse_image_annotation(img[\"annotation\"])\n",
    "                if img_annotation:\n",
    "                    img_entry[\"image_type\"] = img_annotation.get(\"image_type\", \"\")\n",
    "                    img_entry[\"title\"] = img_annotation.get(\"title\", \"\")\n",
    "                    img_entry[\"description\"] = img_annotation.get(\"short_description\", \"\") or img_annotation.get(\"description\", \"\")\n",
    "                    img_entry[\"detailed_description\"] = img_annotation.get(\"detailed_description\", \"\")\n",
    "                    if \"data_extracted\" in img_annotation and img_annotation[\"data_extracted\"]:\n",
    "                        img_entry[\"data_extracted\"] = img_annotation.get(\"data_extracted\", \"\")\n",
    "            \n",
    "            images_data.append(img_entry)\n",
    "        \n",
    "        frontmatter[\"images\"] = images_data\n",
    "    \n",
    "    # G√©n√©rer le YAML\n",
    "    yaml_content = yaml.dump(frontmatter, allow_unicode=True, default_flow_style=False, sort_keys=False)\n",
    "    \n",
    "    return f\"---\\n{yaml_content}---\\n\"\n",
    "\n",
    "\n",
    "def process_ocr_response(\n",
    "    ocr_response: OCRResponse, \n",
    "    output_dir: Path,\n",
    "    include_annotations: bool = True,\n",
    "    source_filename: str = \"\"\n",
    ") -> tuple[str, list[dict]]:\n",
    "    \"\"\"\n",
    "    Traite la r√©ponse OCR et g√©n√®re le markdown avec frontmatter Astro.\n",
    "    \n",
    "    Args:\n",
    "        ocr_response: R√©ponse de l'API OCR\n",
    "        output_dir: Dossier de sortie\n",
    "        include_annotations: Inclure les annotations dans le markdown\n",
    "        source_filename: Nom du fichier source\n",
    "        \n",
    "    Returns:\n",
    "        Tuple (markdown_content, images_info)\n",
    "    \"\"\"\n",
    "    images_dir = output_dir / \"images\"\n",
    "    markdowns = []\n",
    "    images_info = []\n",
    "    \n",
    "    # D'abord, collecter toutes les images pour le frontmatter\n",
    "    for page_idx, page in enumerate(ocr_response.pages):\n",
    "        for img_idx, img in enumerate(page.images):\n",
    "            img_id = img.id\n",
    "            \n",
    "            if hasattr(img, 'image_base64') and img.image_base64:\n",
    "                base64_str = img.image_base64\n",
    "                \n",
    "                # D√©terminer le format\n",
    "                if base64_str.startswith('data:image/png'):\n",
    "                    ext = '.png'\n",
    "                elif base64_str.startswith('data:image/jpeg') or base64_str.startswith('data:image/jpg'):\n",
    "                    ext = '.jpg'\n",
    "                else:\n",
    "                    ext = '.png'\n",
    "                \n",
    "                img_filename = f\"page{page_idx + 1}_img{img_idx + 1}{ext}\"\n",
    "                img_path = images_dir / img_filename\n",
    "                \n",
    "                if save_base64_image(base64_str, str(img_path)):\n",
    "                    print(f\"  ‚úÖ Image sauvegard√©e: {img_filename}\")\n",
    "                    \n",
    "                    img_info = {\n",
    "                        \"id\": img_id,\n",
    "                        \"filename\": img_filename,\n",
    "                        \"page\": page_idx + 1,\n",
    "                        \"position\": {\n",
    "                            \"top_left_x\": getattr(img, 'top_left_x', None),\n",
    "                            \"top_left_y\": getattr(img, 'top_left_y', None),\n",
    "                            \"bottom_right_x\": getattr(img, 'bottom_right_x', None),\n",
    "                            \"bottom_right_y\": getattr(img, 'bottom_right_y', None),\n",
    "                        }\n",
    "                    }\n",
    "                    \n",
    "                    if hasattr(img, 'image_annotation') and img.image_annotation:\n",
    "                        img_info[\"annotation\"] = img.image_annotation\n",
    "                    \n",
    "                    images_info.append(img_info)\n",
    "    \n",
    "    # G√©n√©rer le frontmatter YAML pour Astro\n",
    "    document_annotation = getattr(ocr_response, 'document_annotation', None)\n",
    "    frontmatter = generate_frontmatter(\n",
    "        source_file=source_filename,\n",
    "        document_annotation=document_annotation,\n",
    "        images_info=images_info,\n",
    "        total_pages=len(ocr_response.pages)\n",
    "    )\n",
    "    markdowns.append(frontmatter)\n",
    "    \n",
    "    # Traiter chaque page pour le contenu markdown\n",
    "    for page_idx, page in enumerate(ocr_response.pages):\n",
    "        image_data = {}\n",
    "        \n",
    "        # Pr√©parer les donn√©es des images pour cette page\n",
    "        for img_info in images_info:\n",
    "            if img_info[\"page\"] == page_idx + 1:\n",
    "                img_id = img_info[\"id\"]\n",
    "                relative_path = f\"images/{img_info['filename']}\"\n",
    "                \n",
    "                # Cr√©er l'alt text √† partir de l'annotation\n",
    "                alt_text = img_id\n",
    "                if \"annotation\" in img_info and img_info[\"annotation\"]:\n",
    "                    img_annotation = parse_image_annotation(img_info[\"annotation\"])\n",
    "                    if img_annotation:\n",
    "                        # Construire un alt text descriptif\n",
    "                        parts = []\n",
    "                        if img_annotation.get(\"image_type\"):\n",
    "                            parts.append(f\"[{img_annotation['image_type']}]\")\n",
    "                        if img_annotation.get(\"title\"):\n",
    "                            parts.append(img_annotation[\"title\"])\n",
    "                        elif img_annotation.get(\"short_description\"):\n",
    "                            parts.append(img_annotation[\"short_description\"])\n",
    "                        elif img_annotation.get(\"description\"):\n",
    "                            parts.append(img_annotation[\"description\"])\n",
    "                        \n",
    "                        if parts:\n",
    "                            alt_text = \" - \".join(parts)\n",
    "                \n",
    "                image_data[img_id] = {\n",
    "                    \"path\": relative_path,\n",
    "                    \"alt\": alt_text\n",
    "                }\n",
    "        \n",
    "        # Remplacer les r√©f√©rences d'images dans le markdown\n",
    "        page_markdown = page.markdown\n",
    "        for img_id, data in image_data.items():\n",
    "            old_ref = f\"![{img_id}]({img_id})\"\n",
    "            # Utiliser l'annotation comme alt text\n",
    "            new_ref = f\"![{data['alt']}]({data['path']})\"\n",
    "            page_markdown = page_markdown.replace(old_ref, new_ref)\n",
    "        \n",
    "        markdowns.append(page_markdown)\n",
    "    \n",
    "    return \"\\n\\n\".join(markdowns), images_info\n",
    "\n",
    "\n",
    "print(\"‚úÖ Fonction de traitement OCR avec frontmatter Astro d√©finie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8420c8b",
   "metadata": {},
   "source": [
    "## Fonction principale d'OCR avec Annotations\n",
    "\n",
    "Cette fonction traite un document PDF ou une image et extrait :\n",
    "- Le texte avec structure pr√©serv√©e\n",
    "- Les images/sch√©mas/tableaux avec leurs annotations\n",
    "- Les m√©tadonn√©es du document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60f5d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mistralai.extra import response_format_from_pydantic_model\n",
    "\n",
    "def run_ocr_with_annotations(\n",
    "    file_path: str,\n",
    "    use_bbox_annotation: bool = True,\n",
    "    use_document_annotation: bool = True,\n",
    "    max_pages: int = 8\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Ex√©cute l'OCR avec annotations sur un document.\n",
    "    G√©n√®re un markdown avec frontmatter YAML compatible Astro.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Chemin vers le fichier PDF ou image\n",
    "        use_bbox_annotation: Activer l'annotation des images/graphiques\n",
    "        use_document_annotation: Activer l'annotation du document entier\n",
    "        max_pages: Nombre maximum de pages pour document_annotation (limite API: 8)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionnaire avec les r√©sultats\n",
    "    \"\"\"\n",
    "    file_path = Path(file_path)\n",
    "    base_name = file_path.stem\n",
    "    \n",
    "    print(f\"üîÑ Traitement du fichier: {file_path.name}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Encoder le fichier en base64\n",
    "    base64_content = encode_file_to_base64(str(file_path))\n",
    "    if not base64_content:\n",
    "        return None\n",
    "    \n",
    "    print(\"‚úÖ Fichier encod√© en base64\")\n",
    "    \n",
    "    # D√©terminer le type de document\n",
    "    mime_type = get_mime_type(str(file_path))\n",
    "    is_pdf = mime_type == 'application/pdf'\n",
    "    \n",
    "    # Pr√©parer la configuration du document\n",
    "    if is_pdf:\n",
    "        document_config = {\n",
    "            \"type\": \"document_url\",\n",
    "            \"document_url\": f\"data:{mime_type};base64,{base64_content}\"\n",
    "        }\n",
    "    else:\n",
    "        document_config = {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": f\"data:{mime_type};base64,{base64_content}\"\n",
    "        }\n",
    "    \n",
    "    print(f\"üìÑ Type de document: {mime_type}\")\n",
    "    \n",
    "    # Pr√©parer les param√®tres de l'appel OCR\n",
    "    ocr_params = {\n",
    "        \"model\": \"mistral-ocr-latest\",\n",
    "        \"document\": document_config,\n",
    "        \"include_image_base64\": True\n",
    "    }\n",
    "    \n",
    "    # Ajouter les formats d'annotation si demand√©s\n",
    "    if use_bbox_annotation:\n",
    "        ocr_params[\"bbox_annotation_format\"] = response_format_from_pydantic_model(ImageAnnotation)\n",
    "        print(\"‚úÖ Annotation BBox activ√©e\")\n",
    "    \n",
    "    if use_document_annotation:\n",
    "        ocr_params[\"document_annotation_format\"] = response_format_from_pydantic_model(DocumentAnnotation)\n",
    "        ocr_params[\"pages\"] = list(range(max_pages))  # Limite de 8 pages pour document_annotation\n",
    "        print(f\"‚úÖ Annotation Document activ√©e (max {max_pages} pages)\")\n",
    "    \n",
    "    print(\"\\nüîÑ Appel de l'API Mistral OCR...\")\n",
    "    \n",
    "    # Appel √† l'API OCR\n",
    "    try:\n",
    "        ocr_response = client.ocr.process(**ocr_params)\n",
    "        print(\"‚úÖ OCR termin√© avec succ√®s!\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur lors de l'OCR: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Cr√©er le dossier de sortie\n",
    "    output_dir = create_output_directory(base_name)\n",
    "    print(f\"\\nüìÅ Dossier de sortie cr√©√©: {output_dir}\")\n",
    "    \n",
    "    # Traiter la r√©ponse et g√©n√©rer le markdown avec frontmatter Astro\n",
    "    print(\"\\nüîÑ Traitement des r√©sultats...\")\n",
    "    markdown_content, images_info = process_ocr_response(\n",
    "        ocr_response, \n",
    "        output_dir,\n",
    "        include_annotations=(use_bbox_annotation or use_document_annotation),\n",
    "        source_filename=file_path.name\n",
    "    )\n",
    "    \n",
    "    # Sauvegarder le fichier markdown\n",
    "    markdown_path = output_dir / f\"{base_name}.md\"\n",
    "    with open(markdown_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(markdown_content)\n",
    "    print(f\"‚úÖ Markdown avec frontmatter Astro sauvegard√©: {markdown_path}\")\n",
    "    \n",
    "    # Sauvegarder les m√©tadonn√©es JSON (backup)\n",
    "    metadata = {\n",
    "        \"source_file\": str(file_path),\n",
    "        \"total_pages\": len(ocr_response.pages),\n",
    "        \"total_images\": len(images_info),\n",
    "        \"document_annotation\": ocr_response.document_annotation if hasattr(ocr_response, 'document_annotation') else None,\n",
    "        \"images\": images_info\n",
    "    }\n",
    "    \n",
    "    metadata_path = output_dir / f\"{base_name}_metadata.json\"\n",
    "    with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(metadata, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"‚úÖ M√©tadonn√©es sauvegard√©es: {metadata_path}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(f\"üìä R√©sum√©:\")\n",
    "    print(f\"   - Pages trait√©es: {len(ocr_response.pages)}\")\n",
    "    print(f\"   - Images extraites: {len(images_info)}\")\n",
    "    print(f\"   - Dossier de sortie: {output_dir}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    return {\n",
    "        \"output_dir\": output_dir,\n",
    "        \"markdown_path\": markdown_path,\n",
    "        \"metadata_path\": metadata_path,\n",
    "        \"ocr_response\": ocr_response,\n",
    "        \"markdown_content\": markdown_content,\n",
    "        \"images_info\": images_info,\n",
    "        \"metadata\": metadata\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"‚úÖ Fonction principale d'OCR d√©finie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac90b51e",
   "metadata": {},
   "source": [
    "## Traitement d'un document PDF\n",
    "\n",
    "Exemple avec un des fichiers PDF du dossier `ressources/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165938ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lister les fichiers disponibles dans le dossier ressources\n",
    "ressources_dir = Path(\"ressources\")\n",
    "pdf_files = list(ressources_dir.glob(\"*.pdf\"))\n",
    "\n",
    "print(\"üìÇ Fichiers PDF disponibles dans 'ressources/':\")\n",
    "for i, pdf in enumerate(pdf_files, 1):\n",
    "    print(f\"   {i}. {pdf.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45243ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S√©lectionner le fichier √† traiter (vous pouvez changer l'index ou le nom du fichier)\n",
    "selected_pdf = pdf_files[0] if pdf_files else None\n",
    "\n",
    "if selected_pdf:\n",
    "    print(f\"üìÑ Fichier s√©lectionn√©: {selected_pdf.name}\")\n",
    "    \n",
    "    # Ex√©cuter l'OCR avec annotations\n",
    "    result = run_ocr_with_annotations(\n",
    "        file_path=str(selected_pdf),\n",
    "        use_bbox_annotation=True,\n",
    "        use_document_annotation=True,\n",
    "        max_pages=8\n",
    "    )\n",
    "else:\n",
    "    print(\"‚ùå Aucun fichier PDF trouv√© dans le dossier ressources/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d48879",
   "metadata": {},
   "source": [
    "## Affichage du r√©sultat\n",
    "\n",
    "Visualisation du markdown g√©n√©r√© et des informations extraites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa9f444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher le markdown g√©n√©r√© (si un r√©sultat existe)\n",
    "if result:\n",
    "    print(\"üìÑ Aper√ßu du Markdown g√©n√©r√©:\")\n",
    "    print(\"=\" * 50)\n",
    "    display(Markdown(result[\"markdown_content\"][:5000] + \"\\n\\n...[Tronqu√© pour l'affichage]\" if len(result[\"markdown_content\"]) > 5000 else result[\"markdown_content\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239f8202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les informations sur les images extraites\n",
    "if result and result[\"images_info\"]:\n",
    "    print(\"üñºÔ∏è Images extraites:\")\n",
    "    print(\"=\" * 50)\n",
    "    for img in result[\"images_info\"]:\n",
    "        print(f\"\\nüì∑ {img['filename']} (Page {img['page']})\")\n",
    "        if \"annotation\" in img and img[\"annotation\"]:\n",
    "            print(f\"   Annotation: {img['annotation'][:200]}...\" if len(str(img['annotation'])) > 200 else f\"   Annotation: {img['annotation']}\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è Aucune image extraite du document\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae60c8df",
   "metadata": {},
   "source": [
    "## Traitement de tous les PDFs du dossier ressources\n",
    "\n",
    "Fonction pour traiter tous les documents en lot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d87e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def process_all_documents(\n",
    "    input_dir: str = \"ressources\",\n",
    "    file_pattern: str = \"*.pdf\",\n",
    "    use_bbox_annotation: bool = True,\n",
    "    use_document_annotation: bool = True,\n",
    "    sleep_seconds: float = 2.0\n",
    ") -> list[dict]:\n",
    "    \"\"\"\n",
    "    Traite tous les documents d'un dossier avec pause entre chaque appel API.\n",
    "    G√©n√®re des fichiers markdown avec frontmatter Astro.\n",
    "    \n",
    "    Args:\n",
    "        input_dir: Dossier contenant les documents\n",
    "        file_pattern: Pattern glob pour filtrer les fichiers\n",
    "        use_bbox_annotation: Activer l'annotation des images\n",
    "        use_document_annotation: Activer l'annotation du document\n",
    "        sleep_seconds: Temps d'attente entre chaque document (pour free tier)\n",
    "        \n",
    "    Returns:\n",
    "        Liste des r√©sultats pour chaque document\n",
    "    \"\"\"\n",
    "    input_path = Path(input_dir)\n",
    "    files = list(input_path.glob(file_pattern))\n",
    "    \n",
    "    print(f\"üìÇ {len(files)} fichiers trouv√©s dans '{input_dir}' avec le pattern '{file_pattern}'\")\n",
    "    print(f\"‚è±Ô∏è Pause de {sleep_seconds}s entre chaque document (free tier)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, file_path in enumerate(files, 1):\n",
    "        print(f\"\\n[{i}/{len(files)}] Traitement de: {file_path.name}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        try:\n",
    "            result = run_ocr_with_annotations(\n",
    "                file_path=str(file_path),\n",
    "                use_bbox_annotation=use_bbox_annotation,\n",
    "                use_document_annotation=use_document_annotation\n",
    "            )\n",
    "            \n",
    "            if result:\n",
    "                results.append({\n",
    "                    \"file\": file_path.name,\n",
    "                    \"status\": \"success\",\n",
    "                    \"output_dir\": str(result[\"output_dir\"]),\n",
    "                    \"images_count\": len(result[\"images_info\"])\n",
    "                })\n",
    "            else:\n",
    "                results.append({\n",
    "                    \"file\": file_path.name,\n",
    "                    \"status\": \"failed\",\n",
    "                    \"error\": \"OCR failed\"\n",
    "                })\n",
    "        except Exception as e:\n",
    "            results.append({\n",
    "                \"file\": file_path.name,\n",
    "                \"status\": \"error\",\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "            print(f\"‚ùå Erreur: {e}\")\n",
    "        \n",
    "        # Pause entre chaque document pour respecter les limites du free tier\n",
    "        if i < len(files):\n",
    "            print(f\"\\n‚è≥ Pause de {sleep_seconds}s avant le prochain document...\")\n",
    "            time.sleep(sleep_seconds)\n",
    "    \n",
    "    # R√©sum√© final\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"üìä R√âSUM√â DU TRAITEMENT EN LOT\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    success_count = sum(1 for r in results if r[\"status\"] == \"success\")\n",
    "    failed_count = len(results) - success_count\n",
    "    \n",
    "    print(f\"‚úÖ R√©ussis: {success_count}/{len(results)}\")\n",
    "    print(f\"‚ùå √âchecs: {failed_count}/{len(results)}\")\n",
    "    \n",
    "    if success_count > 0:\n",
    "        print(f\"\\nüìÅ Les fichiers ont √©t√© sauvegard√©s dans le dossier 'output/'\")\n",
    "        print(\"   Chaque sous-dossier contient:\")\n",
    "        print(\"   - Un fichier .md avec frontmatter YAML (compatible Astro)\")\n",
    "        print(\"   - Un fichier _metadata.json avec les donn√©es brutes\")\n",
    "        print(\"   - Un dossier images/ avec les images extraites\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"‚úÖ Fonction de traitement en lot d√©finie (avec pause pour free tier)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7566b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traiter TOUS les fichiers PDF du dossier ressources\n",
    "# Avec pause de 2 secondes entre chaque document pour le free tier\n",
    "\n",
    "batch_results = process_all_documents(\n",
    "    input_dir=\"ressources\",\n",
    "    file_pattern=\"*.pdf\",\n",
    "    use_bbox_annotation=True,\n",
    "    use_document_annotation=True,\n",
    "    sleep_seconds=2.0  # Pause de 2 secondes pour free tier\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7f3076",
   "metadata": {},
   "source": [
    "## Traitement d'une image unique\n",
    "\n",
    "Exemple pour traiter une seule image (PNG, JPEG, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283776f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ocr_on_image(\n",
    "    image_path: str,\n",
    "    use_bbox_annotation: bool = True\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Ex√©cute l'OCR sur une image unique.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Chemin vers l'image\n",
    "        use_bbox_annotation: Activer l'annotation\n",
    "        \n",
    "    Returns:\n",
    "        Dictionnaire avec les r√©sultats\n",
    "    \"\"\"\n",
    "    image_path = Path(image_path)\n",
    "    base_name = image_path.stem\n",
    "    \n",
    "    print(f\"üñºÔ∏è Traitement de l'image: {image_path.name}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Encoder l'image en base64\n",
    "    base64_content = encode_file_to_base64(str(image_path))\n",
    "    if not base64_content:\n",
    "        return None\n",
    "    \n",
    "    print(\"‚úÖ Image encod√©e en base64\")\n",
    "    \n",
    "    # D√©terminer le type MIME\n",
    "    mime_type = get_mime_type(str(image_path))\n",
    "    \n",
    "    # Pr√©parer l'appel OCR\n",
    "    ocr_params = {\n",
    "        \"model\": \"mistral-ocr-latest\",\n",
    "        \"document\": {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": f\"data:{mime_type};base64,{base64_content}\"\n",
    "        },\n",
    "        \"include_image_base64\": True\n",
    "    }\n",
    "    \n",
    "    if use_bbox_annotation:\n",
    "        ocr_params[\"bbox_annotation_format\"] = response_format_from_pydantic_model(ImageAnnotation)\n",
    "    \n",
    "    print(\"üîÑ Appel de l'API Mistral OCR...\")\n",
    "    \n",
    "    try:\n",
    "        ocr_response = client.ocr.process(**ocr_params)\n",
    "        print(\"‚úÖ OCR termin√©!\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Cr√©er le dossier de sortie\n",
    "    output_dir = create_output_directory(base_name)\n",
    "    \n",
    "    # Traiter la r√©ponse\n",
    "    markdown_content, images_info = process_ocr_response(\n",
    "        ocr_response, \n",
    "        output_dir,\n",
    "        include_annotations=use_bbox_annotation\n",
    "    )\n",
    "    \n",
    "    # Sauvegarder\n",
    "    markdown_path = output_dir / f\"{base_name}.md\"\n",
    "    with open(markdown_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(markdown_content)\n",
    "    \n",
    "    print(f\"‚úÖ R√©sultat sauvegard√© dans: {output_dir}\")\n",
    "    \n",
    "    return {\n",
    "        \"output_dir\": output_dir,\n",
    "        \"markdown_path\": markdown_path,\n",
    "        \"markdown_content\": markdown_content,\n",
    "        \"images_info\": images_info\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"‚úÖ Fonction OCR pour images d√©finie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fb7ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple d'utilisation pour une image\n",
    "# image_result = run_ocr_on_image(\"chemin/vers/image.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e46702e",
   "metadata": {},
   "source": [
    "## Structure de sortie pour Astro\n",
    "\n",
    "Apr√®s le traitement, vous obtenez un dossier avec la structure suivante :\n",
    "\n",
    "```\n",
    "output/\n",
    "‚îî‚îÄ‚îÄ nom_du_document/\n",
    "    ‚îú‚îÄ‚îÄ nom_du_document.md          # Fichier Markdown avec frontmatter YAML\n",
    "    ‚îú‚îÄ‚îÄ nom_du_document_metadata.json  # M√©tadonn√©es JSON (backup)\n",
    "    ‚îî‚îÄ‚îÄ images/\n",
    "        ‚îú‚îÄ‚îÄ page1_img1.png          # Images extraites\n",
    "        ‚îú‚îÄ‚îÄ page1_img2.png\n",
    "        ‚îî‚îÄ‚îÄ ...\n",
    "```\n",
    "\n",
    "### Format du frontmatter YAML (compatible Astro)\n",
    "\n",
    "```yaml\n",
    "---\n",
    "source_file: document.pdf\n",
    "total_pages: 5\n",
    "total_images: 3\n",
    "title: \"Titre du document\"\n",
    "language: fr\n",
    "document_type: \"proc√®s-verbal\"\n",
    "summary: \"R√©sum√© du document...\"\n",
    "key_points:\n",
    "  - Point cl√© 1\n",
    "  - Point cl√© 2\n",
    "authors:\n",
    "  - Auteur 1\n",
    "date: \"1995-09-29\"\n",
    "organizations:\n",
    "  - Organisation 1\n",
    "images:\n",
    "  - id: img_001\n",
    "    filename: page1_img1.png\n",
    "    page: 1\n",
    "    image_type: table\n",
    "    title: \"Titre de l'image\"\n",
    "    description: \"Description courte\"\n",
    "    detailed_description: \"Description d√©taill√©e\"\n",
    "---\n",
    "```\n",
    "\n",
    "### Format des images dans le markdown\n",
    "\n",
    "Les images utilisent l'annotation comme texte alternatif :\n",
    "```markdown\n",
    "![{image_type} - {description}](images/page1_img1.png)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1da2a1e",
   "metadata": {},
   "source": [
    "## Mode Multi-Pages : Un Markdown par page\n",
    "\n",
    "Ce mode g√©n√®re un fichier markdown s√©par√© pour chaque page du document.\n",
    "Structure de sortie dans `output_2/` :\n",
    "\n",
    "```\n",
    "output_2/\n",
    "‚îî‚îÄ‚îÄ nom_du_document/\n",
    "    ‚îú‚îÄ‚îÄ page_1.md\n",
    "    ‚îú‚îÄ‚îÄ page_2.md\n",
    "    ‚îú‚îÄ‚îÄ ...\n",
    "    ‚îî‚îÄ‚îÄ images/\n",
    "        ‚îú‚îÄ‚îÄ page1_img1.png\n",
    "        ‚îî‚îÄ‚îÄ ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24caf5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_page_frontmatter(\n",
    "    source_file: str,\n",
    "    page_number: int,\n",
    "    total_pages: int,\n",
    "    document_annotation: str,\n",
    "    page_images_info: list[dict]\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    G√©n√®re le frontmatter YAML pour une page individuelle (Astro).\n",
    "    \n",
    "    Args:\n",
    "        source_file: Nom du fichier source\n",
    "        page_number: Num√©ro de la page (1-indexed)\n",
    "        total_pages: Nombre total de pages\n",
    "        document_annotation: Annotation du document complet\n",
    "        page_images_info: Liste des images de cette page\n",
    "        \n",
    "    Returns:\n",
    "        Frontmatter YAML format√©\n",
    "    \"\"\"\n",
    "    doc_data = parse_document_annotation(document_annotation)\n",
    "    \n",
    "    frontmatter = {\n",
    "        \"source_file\": source_file,\n",
    "        \"page_number\": page_number,\n",
    "        \"total_pages\": total_pages,\n",
    "        \"total_images\": len(page_images_info),\n",
    "    }\n",
    "    \n",
    "    # Ajouter les donn√©es du document si disponibles\n",
    "    if doc_data:\n",
    "        if \"title\" in doc_data:\n",
    "            frontmatter[\"document_title\"] = doc_data.get(\"title\", \"\")\n",
    "        if \"language\" in doc_data:\n",
    "            frontmatter[\"language\"] = doc_data.get(\"language\", \"\")\n",
    "        if \"document_type\" in doc_data:\n",
    "            frontmatter[\"document_type\"] = doc_data.get(\"document_type\", \"\")\n",
    "        # Le r√©sum√© n'est inclus que sur la premi√®re page\n",
    "        if page_number == 1:\n",
    "            if \"summary\" in doc_data:\n",
    "                frontmatter[\"summary\"] = doc_data.get(\"summary\", \"\")\n",
    "            if \"key_points\" in doc_data:\n",
    "                frontmatter[\"key_points\"] = doc_data.get(\"key_points\", [])\n",
    "            if \"authors\" in doc_data:\n",
    "                frontmatter[\"authors\"] = doc_data.get(\"authors\", [])\n",
    "            if \"date\" in doc_data:\n",
    "                frontmatter[\"date\"] = doc_data.get(\"date\", \"\")\n",
    "            if \"organizations\" in doc_data:\n",
    "                frontmatter[\"organizations\"] = doc_data.get(\"organizations\", [])\n",
    "    \n",
    "    # Ajouter les annotations des images de cette page\n",
    "    if page_images_info:\n",
    "        images_data = []\n",
    "        for img in page_images_info:\n",
    "            img_entry = {\n",
    "                \"id\": img.get(\"id\", \"\"),\n",
    "                \"filename\": img.get(\"filename\", \"\"),\n",
    "            }\n",
    "            \n",
    "            if \"annotation\" in img and img[\"annotation\"]:\n",
    "                img_annotation = parse_image_annotation(img[\"annotation\"])\n",
    "                if img_annotation:\n",
    "                    img_entry[\"image_type\"] = img_annotation.get(\"image_type\", \"\")\n",
    "                    img_entry[\"title\"] = img_annotation.get(\"title\", \"\")\n",
    "                    img_entry[\"description\"] = img_annotation.get(\"short_description\", \"\") or img_annotation.get(\"description\", \"\")\n",
    "                    img_entry[\"detailed_description\"] = img_annotation.get(\"detailed_description\", \"\")\n",
    "                    if \"data_extracted\" in img_annotation and img_annotation[\"data_extracted\"]:\n",
    "                        img_entry[\"data_extracted\"] = img_annotation.get(\"data_extracted\", \"\")\n",
    "            \n",
    "            images_data.append(img_entry)\n",
    "        \n",
    "        frontmatter[\"images\"] = images_data\n",
    "    \n",
    "    yaml_content = yaml.dump(frontmatter, allow_unicode=True, default_flow_style=False, sort_keys=False)\n",
    "    return f\"---\\n{yaml_content}---\\n\"\n",
    "\n",
    "\n",
    "def create_output_directory_v2(base_name: str) -> Path:\n",
    "    \"\"\"\n",
    "    Cr√©e le dossier de sortie pour les r√©sultats OCR multi-pages.\n",
    "    \n",
    "    Args:\n",
    "        base_name: Nom de base du document\n",
    "        \n",
    "    Returns:\n",
    "        Chemin du dossier cr√©√©\n",
    "    \"\"\"\n",
    "    output_dir = Path(\"output_2\") / base_name\n",
    "    images_dir = output_dir / \"images\"\n",
    "    \n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    images_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    return output_dir\n",
    "\n",
    "\n",
    "def process_ocr_response_per_page(\n",
    "    ocr_response: OCRResponse, \n",
    "    output_dir: Path,\n",
    "    source_filename: str = \"\"\n",
    ") -> tuple[list[Path], list[dict]]:\n",
    "    \"\"\"\n",
    "    Traite la r√©ponse OCR et g√©n√®re un markdown par page avec frontmatter Astro.\n",
    "    \n",
    "    Args:\n",
    "        ocr_response: R√©ponse de l'API OCR\n",
    "        output_dir: Dossier de sortie\n",
    "        source_filename: Nom du fichier source\n",
    "        \n",
    "    Returns:\n",
    "        Tuple (liste des chemins markdown, images_info)\n",
    "    \"\"\"\n",
    "    images_dir = output_dir / \"images\"\n",
    "    markdown_paths = []\n",
    "    all_images_info = []\n",
    "    \n",
    "    document_annotation = getattr(ocr_response, 'document_annotation', None)\n",
    "    total_pages = len(ocr_response.pages)\n",
    "    \n",
    "    # D'abord, collecter et sauvegarder toutes les images\n",
    "    for page_idx, page in enumerate(ocr_response.pages):\n",
    "        for img_idx, img in enumerate(page.images):\n",
    "            img_id = img.id\n",
    "            \n",
    "            if hasattr(img, 'image_base64') and img.image_base64:\n",
    "                base64_str = img.image_base64\n",
    "                \n",
    "                if base64_str.startswith('data:image/png'):\n",
    "                    ext = '.png'\n",
    "                elif base64_str.startswith('data:image/jpeg') or base64_str.startswith('data:image/jpg'):\n",
    "                    ext = '.jpg'\n",
    "                else:\n",
    "                    ext = '.png'\n",
    "                \n",
    "                img_filename = f\"page{page_idx + 1}_img{img_idx + 1}{ext}\"\n",
    "                img_path = images_dir / img_filename\n",
    "                \n",
    "                if save_base64_image(base64_str, str(img_path)):\n",
    "                    print(f\"  ‚úÖ Image sauvegard√©e: {img_filename}\")\n",
    "                    \n",
    "                    img_info = {\n",
    "                        \"id\": img_id,\n",
    "                        \"filename\": img_filename,\n",
    "                        \"page\": page_idx + 1,\n",
    "                        \"position\": {\n",
    "                            \"top_left_x\": getattr(img, 'top_left_x', None),\n",
    "                            \"top_left_y\": getattr(img, 'top_left_y', None),\n",
    "                            \"bottom_right_x\": getattr(img, 'bottom_right_x', None),\n",
    "                            \"bottom_right_y\": getattr(img, 'bottom_right_y', None),\n",
    "                        }\n",
    "                    }\n",
    "                    \n",
    "                    if hasattr(img, 'image_annotation') and img.image_annotation:\n",
    "                        img_info[\"annotation\"] = img.image_annotation\n",
    "                    \n",
    "                    all_images_info.append(img_info)\n",
    "    \n",
    "    # G√©n√©rer un fichier markdown par page\n",
    "    for page_idx, page in enumerate(ocr_response.pages):\n",
    "        page_number = page_idx + 1\n",
    "        \n",
    "        # Filtrer les images de cette page\n",
    "        page_images = [img for img in all_images_info if img[\"page\"] == page_number]\n",
    "        \n",
    "        # G√©n√©rer le frontmatter pour cette page\n",
    "        frontmatter = generate_page_frontmatter(\n",
    "            source_file=source_filename,\n",
    "            page_number=page_number,\n",
    "            total_pages=total_pages,\n",
    "            document_annotation=document_annotation,\n",
    "            page_images_info=page_images\n",
    "        )\n",
    "        \n",
    "        # Pr√©parer les donn√©es des images pour le remplacement\n",
    "        image_data = {}\n",
    "        for img_info in page_images:\n",
    "            img_id = img_info[\"id\"]\n",
    "            relative_path = f\"images/{img_info['filename']}\"\n",
    "            \n",
    "            alt_text = img_id\n",
    "            if \"annotation\" in img_info and img_info[\"annotation\"]:\n",
    "                img_annotation = parse_image_annotation(img_info[\"annotation\"])\n",
    "                if img_annotation:\n",
    "                    parts = []\n",
    "                    if img_annotation.get(\"image_type\"):\n",
    "                        parts.append(f\"[{img_annotation['image_type']}]\")\n",
    "                    if img_annotation.get(\"title\"):\n",
    "                        parts.append(img_annotation[\"title\"])\n",
    "                    elif img_annotation.get(\"short_description\"):\n",
    "                        parts.append(img_annotation[\"short_description\"])\n",
    "                    elif img_annotation.get(\"description\"):\n",
    "                        parts.append(img_annotation[\"description\"])\n",
    "                    \n",
    "                    if parts:\n",
    "                        alt_text = \" - \".join(parts)\n",
    "            \n",
    "            image_data[img_id] = {\n",
    "                \"path\": relative_path,\n",
    "                \"alt\": alt_text\n",
    "            }\n",
    "        \n",
    "        # Remplacer les r√©f√©rences d'images dans le markdown\n",
    "        page_markdown = page.markdown\n",
    "        for img_id, data in image_data.items():\n",
    "            old_ref = f\"![{img_id}]({img_id})\"\n",
    "            new_ref = f\"![{data['alt']}]({data['path']})\"\n",
    "            page_markdown = page_markdown.replace(old_ref, new_ref)\n",
    "        \n",
    "        # Combiner frontmatter et contenu\n",
    "        full_content = frontmatter + \"\\n\" + page_markdown\n",
    "        \n",
    "        # Sauvegarder le fichier markdown de la page\n",
    "        page_filename = f\"page_{page_number}.md\"\n",
    "        page_path = output_dir / page_filename\n",
    "        \n",
    "        with open(page_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(full_content)\n",
    "        \n",
    "        markdown_paths.append(page_path)\n",
    "        print(f\"  ‚úÖ Page {page_number}/{total_pages} sauvegard√©e: {page_filename}\")\n",
    "    \n",
    "    return markdown_paths, all_images_info\n",
    "\n",
    "\n",
    "print(\"‚úÖ Fonctions pour le mode multi-pages d√©finies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe9bbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ocr_with_annotations_per_page(\n",
    "    file_path: str,\n",
    "    use_bbox_annotation: bool = True,\n",
    "    use_document_annotation: bool = True,\n",
    "    max_pages: int = 8\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Ex√©cute l'OCR avec annotations et g√©n√®re un markdown par page.\n",
    "    Sortie dans output_2/\n",
    "    \n",
    "    Args:\n",
    "        file_path: Chemin vers le fichier PDF ou image\n",
    "        use_bbox_annotation: Activer l'annotation des images/graphiques\n",
    "        use_document_annotation: Activer l'annotation du document entier\n",
    "        max_pages: Nombre maximum de pages pour document_annotation (limite API: 8)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionnaire avec les r√©sultats\n",
    "    \"\"\"\n",
    "    file_path = Path(file_path)\n",
    "    base_name = file_path.stem\n",
    "    \n",
    "    print(f\"üîÑ Traitement du fichier (mode multi-pages): {file_path.name}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Encoder le fichier en base64\n",
    "    base64_content = encode_file_to_base64(str(file_path))\n",
    "    if not base64_content:\n",
    "        return None\n",
    "    \n",
    "    print(\"‚úÖ Fichier encod√© en base64\")\n",
    "    \n",
    "    # D√©terminer le type de document\n",
    "    mime_type = get_mime_type(str(file_path))\n",
    "    is_pdf = mime_type == 'application/pdf'\n",
    "    \n",
    "    # Pr√©parer la configuration du document\n",
    "    if is_pdf:\n",
    "        document_config = {\n",
    "            \"type\": \"document_url\",\n",
    "            \"document_url\": f\"data:{mime_type};base64,{base64_content}\"\n",
    "        }\n",
    "    else:\n",
    "        document_config = {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": f\"data:{mime_type};base64,{base64_content}\"\n",
    "        }\n",
    "    \n",
    "    print(f\"üìÑ Type de document: {mime_type}\")\n",
    "    \n",
    "    # Pr√©parer les param√®tres de l'appel OCR\n",
    "    ocr_params = {\n",
    "        \"model\": \"mistral-ocr-latest\",\n",
    "        \"document\": document_config,\n",
    "        \"include_image_base64\": True\n",
    "    }\n",
    "    \n",
    "    # Ajouter les formats d'annotation si demand√©s\n",
    "    if use_bbox_annotation:\n",
    "        ocr_params[\"bbox_annotation_format\"] = response_format_from_pydantic_model(ImageAnnotation)\n",
    "        print(\"‚úÖ Annotation BBox activ√©e\")\n",
    "    \n",
    "    if use_document_annotation:\n",
    "        ocr_params[\"document_annotation_format\"] = response_format_from_pydantic_model(DocumentAnnotation)\n",
    "        ocr_params[\"pages\"] = list(range(max_pages))\n",
    "        print(f\"‚úÖ Annotation Document activ√©e (max {max_pages} pages)\")\n",
    "    \n",
    "    print(\"\\nüîÑ Appel de l'API Mistral OCR...\")\n",
    "    \n",
    "    # Appel √† l'API OCR\n",
    "    try:\n",
    "        ocr_response = client.ocr.process(**ocr_params)\n",
    "        print(\"‚úÖ OCR termin√© avec succ√®s!\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur lors de l'OCR: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Cr√©er le dossier de sortie (output_2)\n",
    "    output_dir = create_output_directory_v2(base_name)\n",
    "    print(f\"\\nüìÅ Dossier de sortie cr√©√©: {output_dir}\")\n",
    "    \n",
    "    # Traiter la r√©ponse et g√©n√©rer un markdown par page\n",
    "    print(\"\\nüîÑ G√©n√©ration des fichiers markdown par page...\")\n",
    "    markdown_paths, images_info = process_ocr_response_per_page(\n",
    "        ocr_response, \n",
    "        output_dir,\n",
    "        source_filename=file_path.name\n",
    "    )\n",
    "    \n",
    "    # Sauvegarder les m√©tadonn√©es JSON globales\n",
    "    metadata = {\n",
    "        \"source_file\": str(file_path),\n",
    "        \"total_pages\": len(ocr_response.pages),\n",
    "        \"total_images\": len(images_info),\n",
    "        \"document_annotation\": ocr_response.document_annotation if hasattr(ocr_response, 'document_annotation') else None,\n",
    "        \"markdown_files\": [str(p.name) for p in markdown_paths],\n",
    "        \"images\": images_info\n",
    "    }\n",
    "    \n",
    "    metadata_path = output_dir / f\"{base_name}_metadata.json\"\n",
    "    with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(metadata, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"‚úÖ M√©tadonn√©es sauvegard√©es: {metadata_path}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(f\"üìä R√©sum√©:\")\n",
    "    print(f\"   - Pages trait√©es: {len(ocr_response.pages)}\")\n",
    "    print(f\"   - Fichiers markdown cr√©√©s: {len(markdown_paths)}\")\n",
    "    print(f\"   - Images extraites: {len(images_info)}\")\n",
    "    print(f\"   - Dossier de sortie: {output_dir}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    return {\n",
    "        \"output_dir\": output_dir,\n",
    "        \"markdown_paths\": markdown_paths,\n",
    "        \"metadata_path\": metadata_path,\n",
    "        \"ocr_response\": ocr_response,\n",
    "        \"images_info\": images_info,\n",
    "        \"metadata\": metadata\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"‚úÖ Fonction OCR multi-pages d√©finie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533fb8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_documents_per_page(\n",
    "    input_dir: str = \"ressources\",\n",
    "    file_pattern: str = \"*.pdf\",\n",
    "    use_bbox_annotation: bool = True,\n",
    "    use_document_annotation: bool = True,\n",
    "    sleep_seconds: float = 2.0\n",
    ") -> list[dict]:\n",
    "    \"\"\"\n",
    "    Traite tous les documents et g√©n√®re un markdown par page.\n",
    "    Sortie dans output_2/\n",
    "    \n",
    "    Args:\n",
    "        input_dir: Dossier contenant les documents\n",
    "        file_pattern: Pattern glob pour filtrer les fichiers\n",
    "        use_bbox_annotation: Activer l'annotation des images\n",
    "        use_document_annotation: Activer l'annotation du document\n",
    "        sleep_seconds: Temps d'attente entre chaque document (pour free tier)\n",
    "        \n",
    "    Returns:\n",
    "        Liste des r√©sultats pour chaque document\n",
    "    \"\"\"\n",
    "    input_path = Path(input_dir)\n",
    "    files = list(input_path.glob(file_pattern))\n",
    "    \n",
    "    print(f\"üìÇ {len(files)} fichiers trouv√©s dans '{input_dir}' avec le pattern '{file_pattern}'\")\n",
    "    print(f\"‚è±Ô∏è Pause de {sleep_seconds}s entre chaque document (free tier)\")\n",
    "    print(f\"üìÅ Mode multi-pages: un markdown par page dans output_2/\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, file_path in enumerate(files, 1):\n",
    "        print(f\"\\n[{i}/{len(files)}] Traitement de: {file_path.name}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        try:\n",
    "            result = run_ocr_with_annotations_per_page(\n",
    "                file_path=str(file_path),\n",
    "                use_bbox_annotation=use_bbox_annotation,\n",
    "                use_document_annotation=use_document_annotation\n",
    "            )\n",
    "            \n",
    "            if result:\n",
    "                results.append({\n",
    "                    \"file\": file_path.name,\n",
    "                    \"status\": \"success\",\n",
    "                    \"output_dir\": str(result[\"output_dir\"]),\n",
    "                    \"pages_count\": len(result[\"markdown_paths\"]),\n",
    "                    \"images_count\": len(result[\"images_info\"])\n",
    "                })\n",
    "            else:\n",
    "                results.append({\n",
    "                    \"file\": file_path.name,\n",
    "                    \"status\": \"failed\",\n",
    "                    \"error\": \"OCR failed\"\n",
    "                })\n",
    "        except Exception as e:\n",
    "            results.append({\n",
    "                \"file\": file_path.name,\n",
    "                \"status\": \"error\",\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "            print(f\"‚ùå Erreur: {e}\")\n",
    "        \n",
    "        # Pause entre chaque document pour respecter les limites du free tier\n",
    "        if i < len(files):\n",
    "            print(f\"\\n‚è≥ Pause de {sleep_seconds}s avant le prochain document...\")\n",
    "            time.sleep(sleep_seconds)\n",
    "    \n",
    "    # R√©sum√© final\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"üìä R√âSUM√â DU TRAITEMENT EN LOT (MODE MULTI-PAGES)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    success_count = sum(1 for r in results if r[\"status\"] == \"success\")\n",
    "    failed_count = len(results) - success_count\n",
    "    total_pages = sum(r.get(\"pages_count\", 0) for r in results if r[\"status\"] == \"success\")\n",
    "    \n",
    "    print(f\"‚úÖ R√©ussis: {success_count}/{len(results)}\")\n",
    "    print(f\"‚ùå √âchecs: {failed_count}/{len(results)}\")\n",
    "    print(f\"üìÑ Total pages g√©n√©r√©es: {total_pages}\")\n",
    "    \n",
    "    if success_count > 0:\n",
    "        print(f\"\\nüìÅ Les fichiers ont √©t√© sauvegard√©s dans 'output_2/'\")\n",
    "        print(\"   Chaque sous-dossier contient:\")\n",
    "        print(\"   - Un fichier page_X.md par page avec frontmatter YAML\")\n",
    "        print(\"   - Un fichier _metadata.json avec les donn√©es globales\")\n",
    "        print(\"   - Un dossier images/ avec les images extraites\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"‚úÖ Fonction de traitement en lot multi-pages d√©finie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6ff53a",
   "metadata": {},
   "source": [
    "## Ex√©cution : Traitement de tous les PDFs (mode multi-pages)\n",
    "\n",
    "Lance le traitement de tous les fichiers PDF du dossier `ressources/` avec :\n",
    "- Un markdown par page\n",
    "- Pause de 2 secondes entre chaque document (free tier)\n",
    "- Sortie dans `output_2/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157a9cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traiter TOUS les fichiers PDF du dossier ressources (MODE MULTI-PAGES)\n",
    "# Chaque page aura son propre fichier markdown\n",
    "# Pause de 2 secondes entre chaque document pour le free tier\n",
    "\n",
    "batch_results_per_page = process_all_documents_per_page(\n",
    "    input_dir=\"ressources\",\n",
    "    file_pattern=\"*.pdf\",\n",
    "    use_bbox_annotation=True,\n",
    "    use_document_annotation=True,\n",
    "    sleep_seconds=2.0  # Pause de 2 secondes pour free tier\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1f8160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher la structure du dossier de sortie\n",
    "if result:\n",
    "    output_dir = result[\"output_dir\"]\n",
    "    print(f\"üìÅ Structure du dossier de sortie: {output_dir}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for item in output_dir.rglob(\"*\"):\n",
    "        if item.is_file():\n",
    "            relative = item.relative_to(output_dir)\n",
    "            size = item.stat().st_size\n",
    "            print(f\"   üìÑ {relative} ({size:,} bytes)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
