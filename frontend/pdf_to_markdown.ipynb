{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29f32f75",
   "metadata": {},
   "source": [
    "## Installation des d√©pendances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b95ccd",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfba707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import re\n",
    "from typing import Dict, List, Optional\n",
    "from dataclasses import dataclass\n",
    "from PyPDF2 import PdfReader\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac4cb93",
   "metadata": {},
   "source": [
    "## D√©finition des classes et fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ef150b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ParsedPage:\n",
    "    \"\"\"R√©sultat du parsing d'une page.\"\"\"\n",
    "    page_number: int\n",
    "    markdown_content: str\n",
    "    char_count: int\n",
    "    word_count: int\n",
    "    has_tables: bool\n",
    "    extraction_quality: float  # 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d6a6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_from_redundant_elements(\n",
    "    text: str,\n",
    "    headers: List[str],\n",
    "    footers: List[str],\n",
    "    page_patterns: List[str]\n",
    ") -> str:\n",
    "    \"\"\"Nettoie le texte des √©l√©ments redondants.\"\"\"\n",
    "    cleaned = text\n",
    "    \n",
    "    # Supprimer les headers\n",
    "    for header in headers:\n",
    "        cleaned = cleaned.replace(header, \"\")\n",
    "    \n",
    "    # Supprimer les footers\n",
    "    for footer in footers:\n",
    "        cleaned = cleaned.replace(footer, \"\")\n",
    "    \n",
    "    # Supprimer les num√©ros de page\n",
    "    for pattern in page_patterns:\n",
    "        cleaned = re.sub(pattern, \"\", cleaned)\n",
    "    \n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b8db96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _is_likely_header(line: str, all_lines: List[str], index: int) -> bool:\n",
    "    \"\"\"D√©tecte si une ligne est probablement un header.\"\"\"\n",
    "    if len(line) > 80:\n",
    "        return False\n",
    "    \n",
    "    if len(line) < 3:\n",
    "        return False\n",
    "    \n",
    "    if line.isupper() and len(line) > 5:\n",
    "        return True\n",
    "    \n",
    "    if re.match(r\"^(\\d+\\.)+\\s*\\w+|^[IVXLC]+\\.\\s*\\w+\", line):\n",
    "        return True\n",
    "    \n",
    "    if len(line) < 50 and not re.search(r\"[.!?,;:]$\", line):\n",
    "        if index + 1 < len(all_lines):\n",
    "            next_line = all_lines[index + 1].strip()\n",
    "            if not next_line or len(next_line) > len(line):\n",
    "                return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f6aed2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11327553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _determine_header_level(text: str) -> int:\n",
    "    \"\"\"D√©termine le niveau de header (1-4).\"\"\"\n",
    "    if re.match(r\"^\\d+\\.\\d+\\.\\d+\", text):\n",
    "        return 4\n",
    "    if re.match(r\"^\\d+\\.\\d+\", text):\n",
    "        return 3\n",
    "    if re.match(r\"^\\d+\\.\", text):\n",
    "        return 2\n",
    "    \n",
    "    if text.isupper():\n",
    "        if len(text) < 20:\n",
    "            return 1\n",
    "        return 2\n",
    "    \n",
    "    return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc734411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _detect_table_structure(text: str) -> bool:\n",
    "    \"\"\"D√©tecte si le texte contient des structures tabulaires.\"\"\"\n",
    "    patterns = [\n",
    "        r\"\\|.*\\|.*\\|\",\n",
    "        r\"\\t.*\\t.*\\t\",\n",
    "        r\"^\\s*\\S+\\s{3,}\\S+\\s{3,}\\S+\",\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        if re.search(pattern, text, re.MULTILINE):\n",
    "            return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c57b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_extraction_quality(raw_text: str, cleaned_text: str) -> float:\n",
    "    \"\"\"Calcule un score de qualit√© de l'extraction.\"\"\"\n",
    "    if not raw_text:\n",
    "        return 0.0\n",
    "    \n",
    "    conservation_ratio = len(cleaned_text) / len(raw_text) if raw_text else 0\n",
    "    \n",
    "    if not cleaned_text:\n",
    "        return 0.0\n",
    "    \n",
    "    normal_chars = len(\n",
    "        re.findall(\n",
    "            r\"[a-zA-Z0-9√†√¢√§√©√®√™√´√Ø√Æ√¥√π√ª√º√ß√Ä√Ç√Ñ√â√à√ä√ã√è√é√î√ô√õ√ú√á\\s.,!?;:\\-\\'\\\"()\\[\\]{}]\",\n",
    "            cleaned_text,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    char_quality = normal_chars / len(cleaned_text) if cleaned_text else 0\n",
    "    quality = conservation_ratio * 0.3 + char_quality * 0.7\n",
    "    \n",
    "    return min(1.0, max(0.0, quality))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8584d1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _text_to_markdown(text: str, page_num: int) -> str:\n",
    "    \"\"\"Convertit du texte brut en Markdown structur√©.\"\"\"\n",
    "    if not text or not text.strip():\n",
    "        return \"\"\n",
    "    \n",
    "    lines = text.split(\"\\n\")\n",
    "    markdown_lines = []\n",
    "    in_list = False\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        stripped = line.strip()\n",
    "        \n",
    "        if not stripped:\n",
    "            if in_list:\n",
    "                in_list = False\n",
    "            markdown_lines.append(\"\")\n",
    "            continue\n",
    "        \n",
    "        if _is_likely_header(stripped, lines, i):\n",
    "            level = _determine_header_level(stripped)\n",
    "            markdown_lines.append(f\"\\n{'#' * level} {stripped}\\n\")\n",
    "            continue\n",
    "        \n",
    "        if re.match(r\"^[\\-\\‚Ä¢\\*\\‚Üí\\‚ñ∫]\\s+\", stripped):\n",
    "            in_list = True\n",
    "            content = re.sub(r\"^[\\-\\‚Ä¢\\*\\‚Üí\\‚ñ∫]\\s+\", \"\", stripped)\n",
    "            markdown_lines.append(f\"- {content}\")\n",
    "            continue\n",
    "        \n",
    "        if re.match(r\"^\\d+[\\.\\)]\\s+\", stripped):\n",
    "            in_list = True\n",
    "            markdown_lines.append(stripped)\n",
    "            continue\n",
    "        \n",
    "        markdown_lines.append(stripped)\n",
    "    \n",
    "    result = \"\\n\".join(markdown_lines)\n",
    "    result = re.sub(r\"\\n{3,}\", \"\\n\\n\", result)\n",
    "    \n",
    "    return result.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20613f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_text_parser(pdf_path: str) -> Dict:\n",
    "    \"\"\"Extrait le texte d'un PDF et le convertit en Markdown.\"\"\"\n",
    "    print(f\"üìù Extraction texte par parsing: {pdf_path}\")\n",
    "    \n",
    "    # Lire le fichier PDF\n",
    "    with open(pdf_path, 'rb') as f:\n",
    "        pdf_bytes = f.read()\n",
    "    \n",
    "    # Configuration par d√©faut\n",
    "    headers = []\n",
    "    footers = []\n",
    "    page_patterns = [r\"Page\\s+\\d+\"]\n",
    "    \n",
    "    try:\n",
    "        pdf_file = io.BytesIO(pdf_bytes)\n",
    "        pdf_reader = PdfReader(pdf_file)\n",
    "        total_pages = len(pdf_reader.pages)\n",
    "        \n",
    "        parsed_pages: List[ParsedPage] = []\n",
    "        all_markdown_parts: List[str] = []\n",
    "        \n",
    "        for page_num in range(1, total_pages + 1):\n",
    "            page = pdf_reader.pages[page_num - 1]\n",
    "            \n",
    "            try:\n",
    "                raw_text = page.extract_text() or \"\"\n",
    "                cleaned_text = clean_text_from_redundant_elements(\n",
    "                    raw_text, headers, footers, page_patterns\n",
    "                )\n",
    "                \n",
    "                markdown_content = _text_to_markdown(cleaned_text, page_num)\n",
    "                \n",
    "                char_count = len(markdown_content)\n",
    "                word_count = len(markdown_content.split())\n",
    "                has_tables = _detect_table_structure(cleaned_text)\n",
    "                quality = _calculate_extraction_quality(raw_text, cleaned_text)\n",
    "                \n",
    "                parsed_page = ParsedPage(\n",
    "                    page_number=page_num,\n",
    "                    markdown_content=markdown_content,\n",
    "                    char_count=char_count,\n",
    "                    word_count=word_count,\n",
    "                    has_tables=has_tables,\n",
    "                    extraction_quality=quality,\n",
    "                )\n",
    "                \n",
    "                parsed_pages.append(parsed_page)\n",
    "                \n",
    "                if markdown_content.strip():\n",
    "                    all_markdown_parts.append(markdown_content)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ö†Ô∏è Erreur page {page_num}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        full_markdown = \"\\n\\n---\\n\\n\".join(all_markdown_parts)\n",
    "        \n",
    "        total_chars = sum(p.char_count for p in parsed_pages)\n",
    "        total_words = sum(p.word_count for p in parsed_pages)\n",
    "        avg_quality = (\n",
    "            sum(p.extraction_quality for p in parsed_pages) / len(parsed_pages)\n",
    "            if parsed_pages\n",
    "            else 0\n",
    "        )\n",
    "        \n",
    "        print(f\"   ‚úÖ {len(parsed_pages)} pages pars√©es\")\n",
    "        print(f\"   üìä {total_chars} caract√®res, {total_words} mots\")\n",
    "        print(f\"   üìä Qualit√© moyenne: {avg_quality:.0%}\")\n",
    "        \n",
    "        return {\n",
    "            \"error\": None,\n",
    "            \"parsed_pages\": parsed_pages,\n",
    "            \"parsed_markdown\": full_markdown,\n",
    "            \"parsing_stats\": {\n",
    "                \"pages_parsed\": len(parsed_pages),\n",
    "                \"total_chars\": total_chars,\n",
    "                \"total_words\": total_words,\n",
    "                \"average_quality\": round(avg_quality, 2),\n",
    "            },\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"error\": f\"Erreur lors du parsing: {str(e)}\",\n",
    "            \"parsed_pages\": [],\n",
    "            \"parsed_markdown\": \"\",\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d3c86a",
   "metadata": {},
   "source": [
    "## Configuration du fichier PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c5506f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sp√©cifiez le nom du fichier PDF dans le dossier ressources/\n",
    "pdf_filename = \"pv_1995-09-29.Zeendoc.pdf\"  # Changez ceci avec le nom de votre fichier PDF\n",
    "pdf_path = Path(\"ressources\") / pdf_filename\n",
    "\n",
    "# V√©rifier que le fichier existe\n",
    "if not pdf_path.exists():\n",
    "    print(f\"‚ùå Fichier non trouv√©: {pdf_path}\")\n",
    "    print(f\"\\nFichiers disponibles dans ressources/:\")\n",
    "    ressources_dir = Path(\"ressources\")\n",
    "    if ressources_dir.exists():\n",
    "        for file in ressources_dir.iterdir():\n",
    "            if file.is_file():\n",
    "                print(f\"  - {file.name}\")\n",
    "else:\n",
    "    print(f\"‚úÖ Fichier trouv√©: {pdf_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bb71cb",
   "metadata": {},
   "source": [
    "## Extraction du PDF vers Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d444ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex√©cuter l'extraction\n",
    "result = pdf_text_parser(str(pdf_path))\n",
    "\n",
    "if result[\"error\"]:\n",
    "    print(f\"\\n‚ùå Erreur: {result['error']}\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Extraction r√©ussie!\")\n",
    "    print(f\"\\nStatistiques:\")\n",
    "    stats = result[\"parsing_stats\"]\n",
    "    print(f\"  - Pages: {stats['pages_parsed']}\")\n",
    "    print(f\"  - Caract√®res: {stats['total_chars']}\")\n",
    "    print(f\"  - Mots: {stats['total_words']}\")\n",
    "    print(f\"  - Qualit√©: {stats['average_quality']:.0%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fe9fc0",
   "metadata": {},
   "source": [
    "## Affichage du contenu Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc73f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher le contenu Markdown\n",
    "if result[\"parsed_markdown\"]:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"CONTENU MARKDOWN EXTRAIT:\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "    print(result[\"parsed_markdown\"])\n",
    "else:\n",
    "    print(\"Aucun contenu extrait.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e5dae3",
   "metadata": {},
   "source": [
    "## Sauvegarde du Markdown dans un fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150afeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder le r√©sultat dans un fichier .md\n",
    "if result[\"parsed_markdown\"]:\n",
    "    output_filename = pdf_filename.replace(\".pdf\", \".md\")\n",
    "    output_path = Path(\"ressources\") / output_filename\n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(result[\"parsed_markdown\"])\n",
    "    \n",
    "    print(f\"\\nüíæ Fichier Markdown sauvegard√©: {output_path}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Aucun contenu √† sauvegarder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6368dc",
   "metadata": {},
   "source": [
    "## D√©tails par page (optionnel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600e16ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les d√©tails de chaque page\n",
    "if result[\"parsed_pages\"]:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"D√âTAILS PAR PAGE:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    for page in result[\"parsed_pages\"]:\n",
    "        print(f\"\\nPage {page.page_number}:\")\n",
    "        print(f\"  - Caract√®res: {page.char_count}\")\n",
    "        print(f\"  - Mots: {page.word_count}\")\n",
    "        print(f\"  - Tableaux d√©tect√©s: {'Oui' if page.has_tables else 'Non'}\")\n",
    "        print(f\"  - Qualit√©: {page.extraction_quality:.0%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
