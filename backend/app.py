from fastapi import FastAPI, HTTPException, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from typing import Optional, Dict, Any
import uuid
import os
from pathlib import Path
from datetime import datetime
import logging
import wikipedia
import requests
from outils.commandes_vocales import VoiceCommandAgent, CommandResponse, create_default_config
from outils.ocr_processor import OCRProcessor
from outils.statistique_lecture import analyser_texte_lu
from outils.analyse_semantique import SemanticAnalyzer

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173", "http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# Initialiser l'agent de commandes vocales
voice_agent = VoiceCommandAgent()

# Initialiser le processeur OCR
ocr_processor = OCRProcessor()

# Initialiser l'analyseur s√©mantique
semantic_analyzer = SemanticAnalyzer(chroma_db_path="./chromadb_data")

# Dossier de sortie pour les fichiers OCR
OUTPUT_DIR = Path("./output_ocr")


class VoiceCommandRequest(BaseModel):
    """Requete de commande vocale"""
    command: str
    config: Optional[Dict[str, Any]] = None


class TextAnalysisRequest(BaseModel):
    """Requete d'analyse de texte"""
    texte: str


class WikipediaSearchRequest(BaseModel):
    """Requete de recherche Wikipedia"""
    nom: str
    langue: str = "fr"  # Langue par d√©faut: fran√ßais


@app.get("/")
async def read_root():
    return {"msg": "Hello from FastAPI"}


@app.post("/api/voice-command", response_model=CommandResponse)
async def process_voice_command(request: VoiceCommandRequest):
    """
    Traite une commande vocale et retourne l'action a effectuer
    
    Args:
        request: Requete contenant la commande vocale et la config optionnelle
        
    Returns:
        CommandResponse avec l'action detaillee et la config modifiee
    """
    if not request.command or not request.command.strip():
        raise HTTPException(status_code=400, detail="Commande vide")
    
    # Utiliser la config fournie ou cr√©er une config par d√©faut
    config = request.config if request.config else create_default_config()
    
    # Traiter la commande avec l'agent IA
    response = voice_agent.process_command(config, request.command)
    
    return response


@app.post("/api/ocr/process")
async def process_pdf_ocr(
    file: UploadFile = File(...),
    use_bbox_annotation: bool = True,
    use_document_annotation: bool = True,
    max_pages: int = 32,
    generate_analysis: bool = True
):
    """
    Traite un fichier PDF avec l'API Mistral OCR et g√©n√®re un markdown par page.
    Traite jusqu'√† 32 pages par blocs de 8 pages pour contourner la limite API.
    G√©n√®re optionnellement un r√©sum√© et une carte mentale avec analyse s√©mantique.
    
    Args:
        file: Fichier PDF √† traiter
        use_bbox_annotation: Activer l'annotation des images/graphiques
        use_document_annotation: Activer l'annotation du document (appliqu√© aux 8 premi√®res pages)
        max_pages: Nombre maximum de pages √† traiter (limite: 32 pages = 4 blocs de 8)
        generate_analysis: G√©n√©rer le r√©sum√© et la carte mentale (d√©faut: True)
        
    Returns:
        JSON avec les chemins des fichiers g√©n√©r√©s, les m√©tadonn√©es, le r√©sum√© et la mindmap
    """
    # V√©rifier le type de fichier
    if not file.filename.lower().endswith('.pdf'):
        raise HTTPException(
            status_code=400, 
            detail="Seuls les fichiers PDF sont accept√©s"
        )
    
    try:
        # Lire le contenu du fichier
        pdf_content = await file.read()
        
        # Traiter le PDF avec OCR
        result = ocr_processor.process_pdf(
            pdf_content=pdf_content,
            filename=file.filename,
            output_base_dir=OUTPUT_DIR,
            use_bbox_annotation=use_bbox_annotation,
            use_document_annotation=use_document_annotation,
            max_pages=max_pages
        )
        
        response_data = {
            "success": True,
            "message": f"PDF trait√© avec succ√®s: {result['total_pages']} pages, {result['total_images']} images",
            "data": {
                "output_dir": result["output_dir"],
                "markdown_files": result["markdown_files"],
                "metadata_path": result["metadata_path"],
                "total_pages": result["total_pages"],
                "total_images": result["total_images"],
                "document_annotation": result["metadata"].get("document_annotation")
            }
        }
        
        # G√©n√©rer l'analyse s√©mantique si demand√©
        if generate_analysis and result['markdown_files']:
            logger.info("üß† D√©marrage de l'analyse s√©mantique...")
            try:
                # Cr√©er un ID unique pour le document
                document_id = Path(result["output_dir"]).name
                logger.info(f"Document ID: {document_id}")
                logger.info(f"Nombre de fichiers markdown: {len(result['markdown_files'])}")
                
                # Analyser le document
                logger.info("Appel √† semantic_analyzer.analyze_document()...")
                analysis_result = await semantic_analyzer.analyze_document(
                    markdown_files=result['markdown_files'],
                    document_id=document_id,
                    output_dir=Path(result["output_dir"])
                )
                
                logger.info("‚úì Analyse s√©mantique termin√©e avec succ√®s")
                
                # Ajouter les r√©sultats d'analyse √† la r√©ponse
                response_data["data"]["analysis"] = {
                    "summary": analysis_result["summary"],
                    "mindmap": analysis_result["mindmap"],
                    "metrics": analysis_result["metrics"],
                    "files": analysis_result["files"]
                }
                response_data["message"] += f" | Analyse s√©mantique g√©n√©r√©e avec {analysis_result['metrics']['n_clusters']} clusters"
                
            except Exception as analysis_error:
                # Ne pas √©chouer compl√®tement si l'analyse √©choue
                logger.error(f"‚ùå Erreur lors de l'analyse s√©mantique: {str(analysis_error)}")
                logger.exception("Traceback complet de l'erreur d'analyse:")
                response_data["data"]["analysis_error"] = str(analysis_error)
                response_data["message"] += " | Erreur lors de l'analyse s√©mantique"
            finally:
                logger.info(f"üåç Empreinte carbone de l'analyse s√©mantique: {emissions} kg CO2eq")
        return JSONResponse(content=response_data)
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Erreur lors du traitement OCR: {str(e)}"
        )


@app.post("/api/stats/analyse-texte")
async def analyse_texte(request: TextAnalysisRequest):
    """
    Analyse un texte et retourne des statistiques de lecture d√©taill√©es.
    
    Args:
        request: Requ√™te contenant le texte √† analyser
        
    Returns:
        JSON avec toutes les statistiques du texte
    """
    if not request.texte or not request.texte.strip():
        raise HTTPException(
            status_code=400,
            detail="Le texte ne peut pas √™tre vide"
        )
    
    try:
        # Analyser le texte avec la fonction de statistiques
        stats = analyser_texte_lu(request.texte)
        
        return JSONResponse(content={
            "success": True,
            "data": stats
        })
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Erreur lors de l'analyse du texte: {str(e)}"
        )


@app.post("/api/wikipedia/search")
async def search_wikipedia(request: WikipediaSearchRequest):
    """
    Recherche une personne/sujet sur Wikipedia et retourne les premi√®res lignes.
    
    Args:
        request: Requ√™te contenant le nom √† rechercher et la langue
        
    Returns:
        JSON avec la description, l'URL et d'autres informations
    """
    if not request.nom or not request.nom.strip():
        raise HTTPException(
            status_code=400,
            detail="Le nom ne peut pas √™tre vide"
        )
    
    try:
        # Configurer la langue de Wikipedia
        wikipedia.set_lang(request.langue)
        
        # Rechercher la page
        try:
            # Recherche de la page exacte
            page = wikipedia.page(request.nom, auto_suggest=True)
            
            # Extraire le r√©sum√© (premi√®res lignes)
            summary = wikipedia.summary(request.nom, sentences=3, auto_suggest=True)
            
            # Obtenir l'image principale si disponible
            images = page.images[:3] if page.images else []
            
            # Pr√©parer la r√©ponse
            response_data = {
                "success": True,
                "data": {
                    "titre": page.title,
                    "description": summary,
                    "url": page.url,
                    "images": images,
                    "categories": page.categories[:5] if hasattr(page, 'categories') else [],
                    "langue": request.langue,
                    "contenu_complet_disponible": True
                }
            }
            
            return JSONResponse(content=response_data)
            
        except wikipedia.DisambiguationError as e:
            # Page d'homonymie trouv√©e - retourner les options
            return JSONResponse(content={
                "success": False,
                "error": "disambiguation",
                "message": f"Plusieurs r√©sultats trouv√©s pour '{request.nom}'",
                "options": e.options[:10],  # Limiter √† 10 options
                "suggestion": "Veuillez pr√©ciser votre recherche"
            })
            
        except wikipedia.PageError:
            # Page non trouv√©e - essayer une recherche
            search_results = wikipedia.search(request.nom, results=5)
            
            if search_results:
                return JSONResponse(content={
                    "success": False,
                    "error": "page_not_found",
                    "message": f"Aucune page exacte trouv√©e pour '{request.nom}'",
                    "suggestions": search_results,
                    "suggestion": "Voici quelques suggestions"
                })
            else:
                raise HTTPException(
                    status_code=404,
                    detail=f"Aucun r√©sultat trouv√© pour '{request.nom}'"
                )
        
    except Exception as e:
        logger.error(f"Erreur lors de la recherche Wikipedia: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Erreur lors de la recherche: {str(e)}"
        )
