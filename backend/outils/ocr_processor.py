"""
Module pour traiter les documents avec l'API Mistral OCR.
G√©n√®re un fichier markdown par page avec annotations.
"""

import os
import base64
import json
import yaml
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from pydantic import BaseModel, Field
from enum import Enum
from mistralai import Mistral
from mistralai.models import OCRResponse
from mistralai.extra import response_format_from_pydantic_model
from dotenv import load_dotenv

# Charger les variables d'environnement depuis la racine du projet
# Remonter de 2 niveaux depuis backend/outils/ vers la racine
env_path = Path(__file__).parent.parent.parent / '.env'
load_dotenv(dotenv_path=env_path)


# D√©finition des types d'images pour BBox Annotation
class ImageType(str, Enum):
    GRAPH = "graph"
    CHART = "chart"
    TABLE = "table"
    SCHEMA = "schema"
    DIAGRAM = "diagram"
    FIGURE = "figure"
    IMAGE = "image"
    TEXT = "text"
    SIGNATURE = "signature"
    LOGO = "logo"


# Mod√®le pour l'annotation des BBox (images extraites)
class ImageAnnotation(BaseModel):
    image_type: ImageType = Field(..., description="Le type de l'image d√©tect√©e")
    title: str = Field(..., description="Titre ou l√©gende de l'image si disponible")
    short_description: str = Field(..., description="Description courte de l'image en fran√ßais")
    detailed_description: str = Field(..., description="Description d√©taill√©e du contenu de l'image en fran√ßais")
    data_extracted: str = Field(default="", description="Donn√©es extraites si c'est un tableau ou graphique")


# Mod√®le pour l'annotation du document complet
class DocumentAnnotation(BaseModel):
    language: str = Field(..., description="Langue du document en format ISO 639-1")
    title: str = Field(..., description="Titre principal du document")
    document_type: str = Field(..., description="Type de document (rapport, proc√®s-verbal, contrat, etc.)")
    summary: str = Field(..., description="R√©sum√© complet du document en fran√ßais")
    key_points: List[str] = Field(..., description="Points cl√©s du document")
    authors: List[str] = Field(default=[], description="Liste des auteurs ou signataires")
    date: str = Field(default="", description="Date du document si mentionn√©e")
    organizations: List[str] = Field(default=[], description="Organisations ou entit√©s mentionn√©es")


class OCRProcessor:
    """Processeur OCR utilisant l'API Mistral."""
    
    def __init__(self, api_key: Optional[str] = None):
        """
        Initialise le processeur OCR.
        
        Args:
            api_key: Cl√© API Mistral (sinon charg√©e depuis .env)
        """
        self.api_key = api_key or os.getenv("MISTRAL_API_KEY")
        if not self.api_key:
            raise ValueError("MISTRAL_API_KEY non trouv√©e dans l'environnement")
        
        self.client = Mistral(api_key=self.api_key)
    
    @staticmethod
    def encode_file_to_base64(file_content: bytes) -> str:
        """Encode un contenu de fichier en base64."""
        return base64.b64encode(file_content).decode('utf-8')
    
    @staticmethod
    def save_base64_image(base64_string: str, output_path: Path) -> bool:
        """
        Sauvegarde une image base64 vers un fichier.
        
        Args:
            base64_string: Image encod√©e en base64
            output_path: Chemin de sortie
            
        Returns:
            True si succ√®s
        """
        try:
            if base64_string.startswith('data:'):
                base64_string = base64_string.split(',', 1)[1]
            
            image_data = base64.b64decode(base64_string)
            
            with open(output_path, 'wb') as f:
                f.write(image_data)
            return True
        except Exception as e:
            print(f"Erreur lors de la sauvegarde de l'image: {e}")
            return False
    
    @staticmethod
    def parse_document_annotation(annotation_str: str) -> dict:
        """Parse l'annotation du document (JSON string) en dictionnaire."""
        if not annotation_str:
            return {}
        try:
            return json.loads(annotation_str)
        except:
            return {"raw": annotation_str}
    
    @staticmethod
    def parse_image_annotation(annotation_str: str) -> dict:
        """Parse l'annotation d'image (JSON string) en dictionnaire."""
        if not annotation_str:
            return {}
        try:
            return json.loads(annotation_str)
        except:
            return {"description": annotation_str}
    
    def generate_page_frontmatter(
        self,
        source_file: str,
        page_number: int,
        total_pages: int,
        document_annotation: str,
        page_images_info: List[dict]
    ) -> str:
        """
        G√©n√®re le frontmatter YAML pour une page individuelle.
        
        Args:
            source_file: Nom du fichier source
            page_number: Num√©ro de la page (1-indexed)
            total_pages: Nombre total de pages
            document_annotation: Annotation du document complet
            page_images_info: Liste des images de cette page
            
        Returns:
            Frontmatter YAML format√©
        """
        doc_data = self.parse_document_annotation(document_annotation)
        
        frontmatter = {
            "source_file": source_file,
            "page_number": page_number,
            "total_pages": total_pages,
            "total_images": len(page_images_info),
        }
        
        # Ajouter les donn√©es du document si disponibles
        if doc_data:
            if "title" in doc_data:
                frontmatter["document_title"] = doc_data.get("title", "")
            if "language" in doc_data:
                frontmatter["language"] = doc_data.get("language", "")
            if "document_type" in doc_data:
                frontmatter["document_type"] = doc_data.get("document_type", "")
            
            # Le r√©sum√© n'est inclus que sur la premi√®re page
            if page_number == 1:
                if "summary" in doc_data:
                    frontmatter["summary"] = doc_data.get("summary", "")
                if "key_points" in doc_data:
                    frontmatter["key_points"] = doc_data.get("key_points", [])
                if "authors" in doc_data:
                    frontmatter["authors"] = doc_data.get("authors", [])
                if "date" in doc_data:
                    frontmatter["date"] = doc_data.get("date", "")
                if "organizations" in doc_data:
                    frontmatter["organizations"] = doc_data.get("organizations", [])
        
        # Ajouter les annotations des images de cette page
        if page_images_info:
            images_data = []
            for img in page_images_info:
                img_entry = {
                    "id": img.get("id", ""),
                    "filename": img.get("filename", ""),
                }
                
                if "annotation" in img and img["annotation"]:
                    img_annotation = self.parse_image_annotation(img["annotation"])
                    if img_annotation:
                        img_entry["image_type"] = img_annotation.get("image_type", "")
                        img_entry["title"] = img_annotation.get("title", "")
                        img_entry["description"] = img_annotation.get("short_description", "") or img_annotation.get("description", "")
                        img_entry["detailed_description"] = img_annotation.get("detailed_description", "")
                        if "data_extracted" in img_annotation and img_annotation["data_extracted"]:
                            img_entry["data_extracted"] = img_annotation.get("data_extracted", "")
                
                images_data.append(img_entry)
            
            frontmatter["images"] = images_data
        
        yaml_content = yaml.dump(frontmatter, allow_unicode=True, default_flow_style=False, sort_keys=False)
        return f"---\n{yaml_content}---\n"
    
    def process_ocr_response_per_page(
        self,
        ocr_response: OCRResponse,
        output_dir: Path,
        source_filename: str = "",
        page_offset: int = 0,
        total_pages_in_doc: int = None
    ) -> Tuple[List[Path], List[dict]]:
        """
        Traite la r√©ponse OCR et g√©n√®re un markdown par page avec frontmatter.
        
        Args:
            ocr_response: R√©ponse de l'API OCR
            output_dir: Dossier de sortie
            source_filename: Nom du fichier source
            page_offset: Offset pour la num√©rotation des pages (pour traitement par blocs)
            total_pages_in_doc: Nombre total de pages dans le document complet
            
        Returns:
            Tuple (liste des chemins markdown, images_info)
        """
        images_dir = output_dir / "images"
        images_dir.mkdir(parents=True, exist_ok=True)
        
        markdown_paths = []
        all_images_info = []
        
        document_annotation = getattr(ocr_response, 'document_annotation', None)
        total_pages = total_pages_in_doc if total_pages_in_doc else len(ocr_response.pages)
        
        # D'abord, collecter et sauvegarder toutes les images
        for page_idx, page in enumerate(ocr_response.pages):
            actual_page_number = page_offset + page_idx + 1
            
            for img_idx, img in enumerate(page.images):
                img_id = img.id
                
                if hasattr(img, 'image_base64') and img.image_base64:
                    base64_str = img.image_base64
                    
                    if base64_str.startswith('data:image/png'):
                        ext = '.png'
                    elif base64_str.startswith('data:image/jpeg') or base64_str.startswith('data:image/jpg'):
                        ext = '.jpg'
                    else:
                        ext = '.png'
                    
                    img_filename = f"page{actual_page_number}_img{img_idx + 1}{ext}"
                    img_path = images_dir / img_filename
                    
                    if self.save_base64_image(base64_str, img_path):
                        img_info = {
                            "id": img_id,
                            "filename": img_filename,
                            "page": actual_page_number,
                            "position": {
                                "top_left_x": getattr(img, 'top_left_x', None),
                                "top_left_y": getattr(img, 'top_left_y', None),
                                "bottom_right_x": getattr(img, 'bottom_right_x', None),
                                "bottom_right_y": getattr(img, 'bottom_right_y', None),
                            }
                        }
                        
                        if hasattr(img, 'image_annotation') and img.image_annotation:
                            img_info["annotation"] = img.image_annotation
                        
                        all_images_info.append(img_info)
        
        # G√©n√©rer un fichier markdown par page
        for page_idx, page in enumerate(ocr_response.pages):
            actual_page_number = page_offset + page_idx + 1
            
            # Filtrer les images de cette page
            page_images = [img for img in all_images_info if img["page"] == actual_page_number]
            
            # G√©n√©rer le frontmatter pour cette page
            frontmatter = self.generate_page_frontmatter(
                source_file=source_filename,
                page_number=actual_page_number,
                total_pages=total_pages,
                document_annotation=document_annotation,
                page_images_info=page_images
            )
            
            # Pr√©parer les donn√©es des images pour le remplacement
            image_data = {}
            for img_info in page_images:
                img_id = img_info["id"]
                relative_path = f"images/{img_info['filename']}"
                
                alt_text = img_id
                if "annotation" in img_info and img_info["annotation"]:
                    img_annotation = self.parse_image_annotation(img_info["annotation"])
                    if img_annotation:
                        parts = []
                        if img_annotation.get("image_type"):
                            parts.append(f"[{img_annotation['image_type']}]")
                        if img_annotation.get("title"):
                            parts.append(img_annotation["title"])
                        elif img_annotation.get("short_description"):
                            parts.append(img_annotation["short_description"])
                        elif img_annotation.get("description"):
                            parts.append(img_annotation["description"])
                        
                        if parts:
                            alt_text = " - ".join(parts)
                
                image_data[img_id] = {
                    "path": relative_path,
                    "alt": alt_text
                }
            
            # Remplacer les r√©f√©rences d'images dans le markdown
            page_markdown = page.markdown
            for img_id, data in image_data.items():
                old_ref = f"![{img_id}]({img_id})"
                new_ref = f"![{data['alt']}]({data['path']})"
                page_markdown = page_markdown.replace(old_ref, new_ref)
            
            # Combiner frontmatter et contenu
            full_content = frontmatter + "\n" + page_markdown
            
            # Sauvegarder le fichier markdown de la page
            page_filename = f"page_{actual_page_number}.md"
            page_path = output_dir / page_filename
            
            with open(page_path, 'w', encoding='utf-8') as f:
                f.write(full_content)
            
            markdown_paths.append(page_path)
        
        return markdown_paths, all_images_info
    
    def process_pdf(
        self,
        pdf_content: bytes,
        filename: str,
        output_base_dir: Path,
        use_bbox_annotation: bool = True,
        use_document_annotation: bool = True,
        max_pages: int = 32
    ) -> Dict:
        """
        Traite un fichier PDF avec l'API Mistral OCR et g√©n√®re un markdown par page.
        Traite le document par blocs de 8 pages pour contourner la limite API.
        
        Args:
            pdf_content: Contenu binaire du PDF
            filename: Nom du fichier original
            output_base_dir: Dossier de base pour la sortie
            use_bbox_annotation: Activer l'annotation des images
            use_document_annotation: Activer l'annotation du document (uniquement 1er bloc)
            max_pages: Nombre maximum de pages √† traiter (max: 32 pages = 4 blocs de 8)
            
        Returns:
            Dictionnaire avec les r√©sultats du traitement
        """
        base_name = Path(filename).stem
        output_dir = output_base_dir / base_name
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # Encoder le fichier en base64
        base64_content = self.encode_file_to_base64(pdf_content)
        
        # Pr√©parer la configuration du document
        document_config = {
            "type": "document_url",
            "document_url": f"data:application/pdf;base64,{base64_content}"
        }
        
        # Limiter au maximum 32 pages (4 blocs de 8)
        max_pages = min(max_pages, 32)
        
        # Calculer le nombre de blocs n√©cessaires (8 pages par bloc)
        num_blocks = (max_pages + 7) // 8  # Arrondi sup√©rieur
        
        all_markdown_paths = []
        all_images_info = []
        document_annotation = None
        
        # Traiter chaque bloc de 8 pages
        for block_idx in range(num_blocks):
            start_page = block_idx * 8
            end_page = min(start_page + 8, max_pages)
            pages_range = list(range(start_page, end_page))
            
            print(f"üìÑ Traitement du bloc {block_idx + 1}/{num_blocks}: pages {start_page + 1} √† {end_page}")
            
            # Pr√©parer les param√®tres de l'appel OCR pour ce bloc
            ocr_params = {
                "model": "mistral-ocr-latest",
                "document": document_config,
                "include_image_base64": True,
                "pages": pages_range
            }
            
            # Ajouter les formats d'annotation si demand√©s
            if use_bbox_annotation:
                ocr_params["bbox_annotation_format"] = response_format_from_pydantic_model(ImageAnnotation)
            
            # Document annotation uniquement pour le premier bloc
            if use_document_annotation and block_idx == 0:
                ocr_params["document_annotation_format"] = response_format_from_pydantic_model(DocumentAnnotation)
            
            # Appel √† l'API OCR pour ce bloc
            try:
                ocr_response = self.client.ocr.process(**ocr_params)
            except Exception as e:
                raise Exception(f"Erreur lors de l'OCR du bloc {block_idx + 1}: {str(e)}")
            
            # Capturer le document_annotation du premier bloc
            if block_idx == 0 and hasattr(ocr_response, 'document_annotation'):
                document_annotation = ocr_response.document_annotation
            
            # Traiter la r√©ponse et g√©n√©rer un markdown par page
            markdown_paths, images_info = self.process_ocr_response_per_page(
                ocr_response,
                output_dir,
                source_filename=filename,
                page_offset=start_page,
                total_pages_in_doc=max_pages
            )
            
            all_markdown_paths.extend(markdown_paths)
            all_images_info.extend(images_info)
        
        # Sauvegarder les m√©tadonn√©es JSON globales
        metadata = {
            "source_file": filename,
            "total_pages": len(all_markdown_paths),
            "total_images": len(all_images_info),
            "document_annotation": document_annotation,
            "markdown_files": [str(p.name) for p in all_markdown_paths],
            "images": all_images_info,
            "processing_info": {
                "blocks_processed": num_blocks,
                "max_pages_limit": max_pages
            }
        }
        
        metadata_path = output_dir / f"{base_name}_metadata.json"
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        
        return {
            "output_dir": str(output_dir),
            "markdown_files": [str(p) for p in all_markdown_paths],
            "metadata_path": str(metadata_path),
            "total_pages": len(all_markdown_paths),
            "total_images": len(all_images_info),
            "metadata": metadata
        }
